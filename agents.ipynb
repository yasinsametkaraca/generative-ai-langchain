{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have seen the steps regarding chains in previous notebooks. We determined the steps to be taken in these chains. But what happens if language models determine the steps to be taken? We will look for the answer to this question in this notebook. Here, we will enable language models to make their own decisions by using agents.\n",
    "\n",
    "Agents use language models to interact with other agents. In other words, agents choose the action to be taken themselves. We will use two vehicles. One of them is retrievers and the other tool is Search Engine. Search engine answers questions that require up-to-date information.\n"
   ],
   "id": "fb1d1cb3dd442eb3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:16.481027Z",
     "start_time": "2024-05-20T08:03:16.458019Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:17.414355Z",
     "start_time": "2024-05-20T08:03:16.483012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph/\") # WebBaseLoader is a document loader that uses the web to load documents\n",
    "\n",
    "docs = loader.load() # Load the documents from the web\n",
    "print(docs)"
   ],
   "id": "88cf75ba354df95e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\n\\nLangGraph\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy LangChain\\n\\n\\n\\n\\nRelease Notes\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph\\n\\nBy LangChain\\n7 min read\\nJan 17, 2024\\n\\n\\n\\n\\n\\nTL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.Python RepoPython YouTube PlaylistJS RepoIntroductionOne of the things we highlighted in our LangChain v0.1 announcement was the introduction of a new library: LangGraph. LangGraph is built on top of LangChain and completely interoperable with the LangChain ecosystem. It adds new value primarily through the introduction of an easy way to create cyclical graphs. This is often useful when creating agent runtimes.In this blog post, we will first walk through the motivations for LangGraph. We will then cover the basic functionality it provides. We will then spotlight two agent runtimes we\\'ve implemented already. We will then highlight a few of the common modifications to these runtimes we\\'ve heard requests for, and examples of implementing those. We will finish with a preview of what we will be releasing next.MotivationOne of the big value props of LangChain is the ability to easily create custom chains. We\\'ve invested heavily in the functionality for this with LangChain Expression Language. However, so far we\\'ve lacked a method for easily introducing cycles into these chains. Effectively, these chains are directed acyclic graphs (DAGs) - as are most data orchestration frameworks.One of the common patterns we see when people are creating more complex LLM applications is the introduction of cycles into the runtime. These cycles often use the LLM to reason about what to do next in the cycle. A big unlock of LLMs is the ability to use them for these reasoning tasks. This can essentially be thought of as running an LLM in a for-loop. These types of systems are often called agents.An example of why this agentic behavior can be so powerful can be found when considering a typical retrieval augmented generation (RAG) application. In a typical RAG application, a call to a retriever is made that returns some documents. These documents are then passed to an LLM to generate a final answer. While this is often effective, it breaks down in cases when the first retrieval step fails to return any useful results. In this case, it\\'s often ideal if the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever, and use those results instead. Essentially, running an LLM in a loop helps create applications that are more flexible and thus can accomplish more vague use-cases that may not be predefined.These types of applications are often called agents. The simplest - but at the same time most ambitious - form of these is a loop that essentially has two steps:Call the LLM to determine either (a) what actions to take, or (b) what response to give the userTake given actions, and pass back to step 1These steps are repeated until a final response is generated. This is essentially the loop that powers our core AgentExecutor, and is the same logic that caused projects like AutoGPT to rise in prominence. This is simple because it is a relatively simple loop. It is the most ambitious because it offloads pretty much ALL of the decision making and reasoning ability to the LLM.One thing we\\'ve seen in practice as we\\'ve worked the community and companies to put agents into production is that often times more control is needed. You may want to always force an agent to call particular tool first. You may want have more control over how tools are called. You may want to have different prompts for the agent, depending on that state it is in.When talking about these more controlled flows, we internally refer to them as \"state machines\". See the below diagram from our blog on cognitive architectures.These state machines have the power of being able to loop - allowing for handling of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by specifying them as graphs.FunctionalityAt it\\'s core, LangGraph exposes a pretty narrow interface on top of LangChain.StateGraphStateGraph is a class that represents the graph. You initialize this class by passing in a state definition. This state definition represents a central state object that is updated over time. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store).The attributes of this state can be updated in two ways. First, an attribute could be overridden completely. This is useful if you want to nodes to return the new value of an attribute. Second, an attribute could be updated by adding to its value. This is useful if an attribute is a list of actions taken (or something similar) and you want nodes to return new actions taken (and have those automatically added to the attribute).You specify whether an attribute should be overridden or added to when creating the initial state definition. See an example in pseudocode below.from langgraph.graph import StateGraph\\nfrom typing import TypedDict, List, Annotated\\nimport Operator\\n\\n\\nclass State(TypedDict):\\n    input: str\\n    all_actions: Annotated[List[str], operator.add]\\n\\n\\ngraph = StateGraph(State)NodesAfter creating a StateGraph, you then add nodes with graph.add_node(name, value) syntax. The name parameter should be a string that we will use to refer to the node when adding edges. The value parameter should be either a function or LCEL runnable that will be called. This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.See an example in pseudocode below.graph.add_node(\"model\", model)\\ngraph.add_node(\"tools\", tool_executor)There is also a special END node that is used to represent the end of the graph. It is important that your cycles be able to end eventually!from langgraph.graph import ENDEdgesAfter adding nodes, you can then add edges to create the graph. There are a few types of edges.The Starting EdgeThis is the edge that connects the start of the graph to a particular node. This will make it so that that node is the first one called when input is passed to the graph. Pseudocode for that is:graph.set_entry_point(\"model\")Normal EdgesThese are edges where one node should ALWAYS be called after another. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool.graph.add_edge(\"tools\", \"model\")Conditional EdgesThese are where a function (often powered by an LLM) is used to determine which node to go to first. To create this edge, you need to pass in three things:The upstream node: the output of this node will be looked at to determine what to do nextA function: this will be called to determine which node to call next. It should return a stringA mapping: this mapping will be used to map the output of the function in (2) to another node. The keys should be possible values that the function in (2) could return. The values should be names of nodes to go to if that value is returned.An example of this could be that after a model is called we either exit the graph and return to the user, or we call a tool - depending on what a user decides! See an example in pseudocode below:graph.add_conditional_edge(\\n    \"model\",\\n    should_continue,\\n    {\\n        \"end\": END,\\n        \"continue\": \"tools\"\\n    }\\n)CompileAfter we define our graph, we can compile it into a runnable! This simply takes the graph definition we\\'ve created so far an returns a runnable. This runnable exposes all the same method as LangChain runnables (.invoke, .stream, .astream_log, etc) allowing it to be called in the same manner as a chain.app = graph.compile()Agent ExecutorWe\\'ve recreated the canonical LangChain AgentExecutor with LangGraph. This will allow you to use existing LangChain agents, but allow you to more easily modify the internals of the AgentExecutor. The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)from typing import TypedDict, Annotated, List, Union\\nfrom langchain_core.agents import AgentAction, AgentFinish\\nfrom langchain_core.messages import BaseMessage\\nimport operator\\n\\n\\nclass AgentState(TypedDict):\\n   input: str\\n   chat_history: list[BaseMessage]\\n   agent_outcome: Union[AgentAction, AgentFinish, None]\\n   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add] See this notebook for how to get startedChat Agent ExecutorOne common trend we\\'ve seen is that more and more models are \"chat\" models which operate on a list of messages. This models are often the ones equipped with things like function calling, which make agent-like experiences much more feasible. When working with these types of models, it is often intuitive to represent the state of an agent as a list of messages.As such, we\\'ve created an agent runtime that works with this state. The input is a list of messages, and nodes just simply add to this list of messages over time.from typing import TypedDict, Annotated, Sequence\\nimport operator\\nfrom langchain_core.messages import BaseMessage\\n\\n\\nclass AgentState(TypedDict):\\n    messages: Annotated[Sequence[BaseMessage], operator.add] See this notebook for how to get startedModificationsOne of the big benefits of LangGraph is that it exposes the logic of AgentExecutor in a far more natural and modifiable way. We\\'ve provided a few examples of modifications that we\\'ve heard requests for:Force Calling a ToolFor when you always want to make an agent call a tool first. For Agent Executor and Chat Agent Executor.Human-in-the-loopHow to add a human-in-the-loop step before calling tools. For Agent Executor and Chat Agent Executor.Managing Agent StepsFor adding custom logic on how to handle the intermediate steps an agent might take (useful for when there\\'s a lot of steps). For Agent Executor and Chat Agent Executor.Returning Output in a Specific FormatHow to make the agent return output in a specific format using function calling. Only for Chat Agent Executor.Dynamically Returning the Output of a Tool DirectlySometimes you may want to return the output of a tool directly. We provide an easy way to do with the return_direct parameter in LangChain. However, this makes it so that the output of a tool is ALWAYS returned directly. Sometimes, you may want to let the LLM choose whether to return the response directly or not. Only for Chat Agent Executor.Future WorkWe\\'re incredibly excited about the possibility of LangGraph enabling more custom and powerful agent runtimes. Some of the things we are looking to implement in the near future:More advanced agent runtimes from academia (LLM Compiler, plan-and-solve, etc)Stateful tools (allowing tools to modify some state)More controlled human-in-the-loop workflowsMulti-agent workflowsIf any of these resonate with you, please feel free to add an example notebook in the LangGraph repo, or reach out to us at hello@langchain.dev for more involved collaboration!\\n\\n\\nTags\\nBy LangChain\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\nYou might also like\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReflection Agents\\n\\n\\nagents\\n6 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlan-and-Execute Agents\\n\\n\\nBy LangChain\\n5 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/19] LangChain Release Notes\\n\\n\\nBy LangChain\\n1 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients and employees\\n\\n\\nBy LangChain\\n3 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/5] LangChain Release Notes\\n\\n\\nBy LangChain\\n4 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain Partners with CommandBar on their Copilot User Assistant\\n\\n\\nBy LangChain\\n2 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2024\\n        \\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:17.444881Z",
     "start_time": "2024-05-20T08:03:17.415333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter() # RecursiveCharacterTextSplitter is a text splitter that splits the text into characters recursively\n",
    "\n",
    "documents = text_splitter.split_documents(docs) # Split the documents into characters. Documents are a list of strings\n",
    "print(documents)"
   ],
   "id": "bf80d02805edc68b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='LangGraph\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy LangChain\\n\\n\\n\\n\\nRelease Notes\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph\\n\\nBy LangChain\\n7 min read\\nJan 17, 2024', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'}), Document(page_content='TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.Python RepoPython YouTube PlaylistJS RepoIntroductionOne of the things we highlighted in our LangChain v0.1 announcement was the introduction of a new library: LangGraph. LangGraph is built on top of LangChain and completely interoperable with the LangChain ecosystem. It adds new value primarily through the introduction of an easy way to create cyclical graphs. This is often useful when creating agent runtimes.In this blog post, we will first walk through the motivations for LangGraph. We will then cover the basic functionality it provides. We will then spotlight two agent runtimes we\\'ve implemented already. We will then highlight a few of the common modifications to these runtimes we\\'ve heard requests for, and examples of implementing those. We will finish with a preview of what we will be releasing next.MotivationOne of the big value props of LangChain is the ability to easily create custom chains. We\\'ve invested heavily in the functionality for this with LangChain Expression Language. However, so far we\\'ve lacked a method for easily introducing cycles into these chains. Effectively, these chains are directed acyclic graphs (DAGs) - as are most data orchestration frameworks.One of the common patterns we see when people are creating more complex LLM applications is the introduction of cycles into the runtime. These cycles often use the LLM to reason about what to do next in the cycle. A big unlock of LLMs is the ability to use them for these reasoning tasks. This can essentially be thought of as running an LLM in a for-loop. These types of systems are often called agents.An example of why this agentic behavior can be so powerful can be found when considering a typical retrieval augmented generation (RAG) application. In a typical RAG application, a call to a retriever is made that returns some documents. These documents are then passed to an LLM to generate a final answer. While this is often effective, it breaks down in cases when the first retrieval step fails to return any useful results. In this case, it\\'s often ideal if the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever, and use those results instead. Essentially, running an LLM in a loop helps create applications that are more flexible and thus can accomplish more vague use-cases that may not be predefined.These types of applications are often called agents. The simplest - but at the same time most ambitious - form of these is a loop that essentially has two steps:Call the LLM to determine either (a) what actions to take, or (b) what response to give the userTake given actions, and pass back to step 1These steps are repeated until a final response is generated. This is essentially the loop that powers our core AgentExecutor, and is the same logic that caused projects like AutoGPT to rise in prominence. This is simple because it is a relatively simple loop. It is the most ambitious because it offloads pretty much ALL of the decision making and reasoning ability to the LLM.One thing we\\'ve seen in practice as we\\'ve worked the community and companies to put agents into production is that often times more control is needed. You may want to always force an agent to call particular tool first. You may want have more control over how tools are called. You may want to have different prompts for the agent, depending on that state it is in.When talking about these more controlled flows, we internally refer to them as \"state machines\". See the below diagram from our blog on cognitive architectures.These state machines have the power of being able to loop - allowing for handling of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'}), Document(page_content=\"of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by specifying them as graphs.FunctionalityAt it's core, LangGraph exposes a pretty narrow interface on top of LangChain.StateGraphStateGraph is a class that represents the graph. You initialize this class by passing in a state definition. This state definition represents a central state object that is updated over time. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store).The attributes of this state can be updated in two ways. First, an attribute could be overridden completely. This is useful if you want to nodes to return the new value of an attribute. Second, an attribute could be updated by adding to its value. This is useful if an attribute is a list of actions taken (or something similar) and you want nodes to return new actions taken (and have those automatically added to the attribute).You specify whether an attribute should be overridden or added to when creating the initial state definition. See an example in pseudocode below.from langgraph.graph import StateGraph\", metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'}), Document(page_content='from typing import TypedDict, List, Annotated\\nimport Operator', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'}), Document(page_content='class State(TypedDict):\\n    input: str\\n    all_actions: Annotated[List[str], operator.add]\\n\\n\\ngraph = StateGraph(State)NodesAfter creating a StateGraph, you then add nodes with graph.add_node(name, value) syntax. The name parameter should be a string that we will use to refer to the node when adding edges. The value parameter should be either a function or LCEL runnable that will be called. This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.See an example in pseudocode below.graph.add_node(\"model\", model)\\ngraph.add_node(\"tools\", tool_executor)There is also a special END node that is used to represent the end of the graph. It is important that your cycles be able to end eventually!from langgraph.graph import ENDEdgesAfter adding nodes, you can then add edges to create the graph. There are a few types of edges.The Starting EdgeThis is the edge that connects the start of the graph to a particular node. This will make it so that that node is the first one called when input is passed to the graph. Pseudocode for that is:graph.set_entry_point(\"model\")Normal EdgesThese are edges where one node should ALWAYS be called after another. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool.graph.add_edge(\"tools\", \"model\")Conditional EdgesThese are where a function (often powered by an LLM) is used to determine which node to go to first. To create this edge, you need to pass in three things:The upstream node: the output of this node will be looked at to determine what to do nextA function: this will be called to determine which node to call next. It should return a stringA mapping: this mapping will be used to map the output of the function in (2) to another node. The keys should be possible values that the function in (2) could return. The values should be names of nodes to go to if that value is returned.An example of this could be that after a model is called we either exit the graph and return to the user, or we call a tool - depending on what a user decides! See an example in pseudocode below:graph.add_conditional_edge(\\n    \"model\",\\n    should_continue,\\n    {\\n        \"end\": END,\\n        \"continue\": \"tools\"\\n    }\\n)CompileAfter we define our graph, we can compile it into a runnable! This simply takes the graph definition we\\'ve created so far an returns a runnable. This runnable exposes all the same method as LangChain runnables (.invoke, .stream, .astream_log, etc) allowing it to be called in the same manner as a chain.app = graph.compile()Agent ExecutorWe\\'ve recreated the canonical LangChain AgentExecutor with LangGraph. This will allow you to use existing LangChain agents, but allow you to more easily modify the internals of the AgentExecutor. The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)from typing import TypedDict, Annotated, List, Union\\nfrom langchain_core.agents import AgentAction, AgentFinish\\nfrom langchain_core.messages import BaseMessage\\nimport operator', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'}), Document(page_content='class AgentState(TypedDict):\\n   input: str\\n   chat_history: list[BaseMessage]\\n   agent_outcome: Union[AgentAction, AgentFinish, None]\\n   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add] See this notebook for how to get startedChat Agent ExecutorOne common trend we\\'ve seen is that more and more models are \"chat\" models which operate on a list of messages. This models are often the ones equipped with things like function calling, which make agent-like experiences much more feasible. When working with these types of models, it is often intuitive to represent the state of an agent as a list of messages.As such, we\\'ve created an agent runtime that works with this state. The input is a list of messages, and nodes just simply add to this list of messages over time.from typing import TypedDict, Annotated, Sequence\\nimport operator\\nfrom langchain_core.messages import BaseMessage\\n\\n\\nclass AgentState(TypedDict):\\n    messages: Annotated[Sequence[BaseMessage], operator.add] See this notebook for how to get startedModificationsOne of the big benefits of LangGraph is that it exposes the logic of AgentExecutor in a far more natural and modifiable way. We\\'ve provided a few examples of modifications that we\\'ve heard requests for:Force Calling a ToolFor when you always want to make an agent call a tool first. For Agent Executor and Chat Agent Executor.Human-in-the-loopHow to add a human-in-the-loop step before calling tools. For Agent Executor and Chat Agent Executor.Managing Agent StepsFor adding custom logic on how to handle the intermediate steps an agent might take (useful for when there\\'s a lot of steps). For Agent Executor and Chat Agent Executor.Returning Output in a Specific FormatHow to make the agent return output in a specific format using function calling. Only for Chat Agent Executor.Dynamically Returning the Output of a Tool DirectlySometimes you may want to return the output of a tool directly. We provide an easy way to do with the return_direct parameter in LangChain. However, this makes it so that the output of a tool is ALWAYS returned directly. Sometimes, you may want to let the LLM choose whether to return the response directly or not. Only for Chat Agent Executor.Future WorkWe\\'re incredibly excited about the possibility of LangGraph enabling more custom and powerful agent runtimes. Some of the things we are looking to implement in the near future:More advanced agent runtimes from academia (LLM Compiler, plan-and-solve, etc)Stateful tools (allowing tools to modify some state)More controlled human-in-the-loop workflowsMulti-agent workflowsIf any of these resonate with you, please feel free to add an example notebook in the LangGraph repo, or reach out to us at hello@langchain.dev for more involved collaboration!\\n\\n\\nTags\\nBy LangChain\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\nYou might also like\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReflection Agents\\n\\n\\nagents\\n6 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlan-and-Execute Agents\\n\\n\\nBy LangChain\\n5 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/19] LangChain Release Notes\\n\\n\\nBy LangChain\\n1 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients and employees\\n\\n\\nBy LangChain\\n3 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/5] LangChain Release Notes\\n\\n\\nBy LangChain\\n4 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain Partners with CommandBar on their Copilot User Assistant\\n\\n\\nBy LangChain\\n2 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2024', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'})]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:18.247617Z",
     "start_time": "2024-05-20T08:03:17.445845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings() # To convert the text to vectors, we use OpenAIEmbeddings"
   ],
   "id": "737071e0eb29bbb1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:20.185589Z",
     "start_time": "2024-05-20T08:03:18.249784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector = FAISS.from_documents(documents, embeddings) # The data was first converted into numerical representations with embeddings and then indexed into the database. Vectors were made quickly searchable using FAISS."
   ],
   "id": "c51641be9c183df3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:20.200764Z",
     "start_time": "2024-05-20T08:03:20.186574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vector.as_retriever() # Retriever has data about langgraph in db.\n",
    "# We create a retriever to capture this indexed data."
   ],
   "id": "90ceac4546e45055",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:20.652071Z",
     "start_time": "2024-05-20T08:03:20.201764Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.get_relevant_documents(\"What is LangGraph\")[0] # We can get the relevant documents with the retriever.",
   "id": "c100eaab548de43b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.Python RepoPython YouTube PlaylistJS RepoIntroductionOne of the things we highlighted in our LangChain v0.1 announcement was the introduction of a new library: LangGraph. LangGraph is built on top of LangChain and completely interoperable with the LangChain ecosystem. It adds new value primarily through the introduction of an easy way to create cyclical graphs. This is often useful when creating agent runtimes.In this blog post, we will first walk through the motivations for LangGraph. We will then cover the basic functionality it provides. We will then spotlight two agent runtimes we\\'ve implemented already. We will then highlight a few of the common modifications to these runtimes we\\'ve heard requests for, and examples of implementing those. We will finish with a preview of what we will be releasing next.MotivationOne of the big value props of LangChain is the ability to easily create custom chains. We\\'ve invested heavily in the functionality for this with LangChain Expression Language. However, so far we\\'ve lacked a method for easily introducing cycles into these chains. Effectively, these chains are directed acyclic graphs (DAGs) - as are most data orchestration frameworks.One of the common patterns we see when people are creating more complex LLM applications is the introduction of cycles into the runtime. These cycles often use the LLM to reason about what to do next in the cycle. A big unlock of LLMs is the ability to use them for these reasoning tasks. This can essentially be thought of as running an LLM in a for-loop. These types of systems are often called agents.An example of why this agentic behavior can be so powerful can be found when considering a typical retrieval augmented generation (RAG) application. In a typical RAG application, a call to a retriever is made that returns some documents. These documents are then passed to an LLM to generate a final answer. While this is often effective, it breaks down in cases when the first retrieval step fails to return any useful results. In this case, it\\'s often ideal if the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever, and use those results instead. Essentially, running an LLM in a loop helps create applications that are more flexible and thus can accomplish more vague use-cases that may not be predefined.These types of applications are often called agents. The simplest - but at the same time most ambitious - form of these is a loop that essentially has two steps:Call the LLM to determine either (a) what actions to take, or (b) what response to give the userTake given actions, and pass back to step 1These steps are repeated until a final response is generated. This is essentially the loop that powers our core AgentExecutor, and is the same logic that caused projects like AutoGPT to rise in prominence. This is simple because it is a relatively simple loop. It is the most ambitious because it offloads pretty much ALL of the decision making and reasoning ability to the LLM.One thing we\\'ve seen in practice as we\\'ve worked the community and companies to put agents into production is that often times more control is needed. You may want to always force an agent to call particular tool first. You may want have more control over how tools are called. You may want to have different prompts for the agent, depending on that state it is in.When talking about these more controlled flows, we internally refer to them as \"state machines\". See the below diagram from our blog on cognitive architectures.These state machines have the power of being able to loop - allowing for handling of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by', metadata={'source': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph', 'language': 'en'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:20.667089Z",
     "start_time": "2024-05-20T08:03:20.653075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.tools.retriever import create_retriever_tool # We created a tool to capture the information we want\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langgraph_search\", # Tool name.  This will be passed to the language model, so should be unique and somewhat descriptive.\n",
    "    \"Search for information about LangGraph. For any question about LangGraph, you must use this tool!\", # The description for the tool. This will be passed to the language model, so should be descriptive.\n",
    ") # We create a retriever tool to get the relevant documents. It return tool class to pass to an agent. "
   ],
   "id": "db1e54331b9937a8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will use tavily as the Search tool. Tavily was developed specifically for artificial intelligence agents. ",
   "id": "366069761587cc6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:20.682519Z",
     "start_time": "2024-05-20T08:03:20.668075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults # Tool that queries the Tavily Search API and gets back json.\n",
    "# tavily is a search engine tool that uses the Tavily Search API to search for information.\n",
    "\n",
    "search = TavilySearchResults() # We created a tool to search."
   ],
   "id": "a3dad3060f93f3d5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:22.194837Z",
     "start_time": "2024-05-20T08:03:20.683518Z"
    }
   },
   "cell_type": "code",
   "source": "search.invoke(\"Which is the best language model?\") # We can get the search results with the search tool.",
   "id": "b172035353a290ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.techtarget.com/WhatIs/feature/12-of-the-best-large-language-models',\n",
       "  'content': 'Process mining is a technique that interprets logs from enterprise applications -- like customer resource management (CRM) and ...\\nOrganizational change management (OCM) is a type of change management framework for managing the effect of new business processes...\\nAn employee resource group is a workplace club or more formally realized affinity group organized around a shared interest or ...\\nEmployee training and development is a set of activities and programs designed to enhance the knowledge, skills and abilities of ...\\nEmployee sentiment analysis is the use of natural language processing and other AI techniques to automatically analyze employee ...\\nCustomer profiling is the detailed and systematic process of constructing a clear portrait of a company\\'s ideal customer by ...\\nCustomer insight, also known as consumer insight, is the understanding and interpretation of customer data, behaviors and ...\\n The possession factor, in a security context, is a category of user authentication credentials based on items that the user has ...\\nA CISO as a service (CISOaaS) is the outsourcing of CISO (chief information security officer) and information security leadership...\\nCyber hygiene, or cybersecurity hygiene, is a set of practices individuals and organizations perform regularly to maintain the ...\\nRadical innovation is an invention that destroys or supplants an existing business model.\\n Generative AI challenges that businesses should consider\\nGenerative AI ethics: 8 biggest concerns\\nGenerative AI landscape: Potential future trends\\nGenerative models: VAEs, GANs, diffusion, transformers, NeRFs\\nAI content generators to explore\\n5G standalone (5G SA) is a cellular infrastructure built specifically for 5G services by implementing 5G standards and protocols ...\\n \"\\nSome of the most well-known language models today are based on the transformer model, including the generative pre-trained transformer series of LLMs and bidirectional encoder representations from transformers (BERT).\\n 16 of the best large language models\\nLarge language models have been affecting search for years and have been brought to the forefront by ChatGPT and other chatbots.\\n'},\n",
       " {'url': 'https://beebom.com/best-large-language-models-llms/',\n",
       "  'content': 'Instead, the company has used publicly available data from CommonCrawl, C4, GitHub, ArXiv, Wikipedia, StackExchange, and more.\\nSimply put, after the release of the LLaMA model by Meta, the open-source community saw rapid innovation and came up with novel techniques to make smaller and more efficient models.\\n Having said that, do keep in mind, LLaMA has been released for research only and can’t be used commercially unlike the Falcon model by the TII.\\nTalking about the LLaMA 65B model, it has shown amazing capability in most use cases. Released in March 2023, the GPT-4 model has showcased tremendous capabilities with complex reasoning understanding, advanced coding capability, proficiency in multiple academic exams, skills that exhibit human-level performance, and much more\\nIn fact, it’s the first multimodal model that can accept both texts and images as input. Falcon\\nFalcon is the first open-source large language model on this list, and it has outranked all the open-source models released so far, including LLaMA, StableLM, MPT, and more. Overall, the OpenAI GPT-4 model is by far the best LLM you can use in 2023, and I strongly recommend subscribing to ChatGPT Plus if you intend to use it for serious work.'},\n",
       " {'url': 'https://vectara.com/blog/top-large-language-models-llms-gpt-4-llama-gato-bloom-and-when-to-choose-one-over-the-other/',\n",
       "  'content': 'Recommended Content\\nRetrieval and Search\\nSeptember 26, 2023 by Suleman Kazi\\n& Vivek Sourabh\\n|\\n9 min Read\\nRetrieval and Search\\nOctober 10, 2023 by Ofer Mendelevitch\\n|\\n8 min Read\\nData ingestion\\nSeptember 20, 2023 by Ofer Mendelevitch\\n|\\n7 min Read\\nCOMPANY OVERVIEW\\nVectara: Hybrid Search and With multiple fine tuning scripts and flavors available online, Llama Chat is our pick if you want to fine-tune a model for your own application\\nFALCON\\nTechnology Innovation Institute, Multiple Sizes, Downloadable\\nOur pick for a self-hosted model for high quality, if compute isn’t an issue\\nThe FALCON series of models were developed by the UAE’s Technology Innovation Institute (TII) and come in 180B, 40B, 7.5B and 1.3B versions. LLaMA 2\\nMeta AI, Multiple Sizes, Downloadable\\nOur pick for best model for code understanding and completion\\nOur pick for a model to fine-tune for commercial and research purposes\\nReleased in July 2023, Llama2 is Meta AI’s next generation of open source language understanding model. The language modeling space has seen amazing progress since the Attention is All You Need paper by Google in 2017 which introduced the concept of transformers (The ‘T’ in all the GPT models you‘ve probably heard about), taking the natural language processing world by storm and being the base of pretty much every advance in NLP since then.\\n MT-NLG\\nNvidia / Microsoft, 530 billion parameters, API Access by application\\nMT-NLG (Megatron-Turing Natural Language Generation), announced in October 2021, \\xa0uses the architecture of the transformer-based Megatron to generate coherent and contextually relevant text for a range of tasks, including completion prediction, reading comprehension, commonsense reasoning, natural language inferences, word sense disambiguation.\\n'},\n",
       " {'url': 'https://zapier.com/blog/best-llm/',\n",
       "  'content': 'ChatGPT\\n175 billion+\\nAPI\\nGemini\\nGoogle\\nSome queries on Bard\\nNano: 1.8 & 3.25 billion; others unknown\\nAPI\\nPaLM 2\\nGoogle\\nGoogle Bard, Docs, Gmail, and other Google apps\\n340 billion\\nAPI\\nLlama 2\\nMeta\\nUndisclosed\\n7, 13, and 70 billion\\nOpen source\\nVicuna\\nLMSYS Org\\nChatbot Arena\\n7, 13, and 33 billion\\nOpen source\\nClaude 2\\nAnthropic\\nSlack, Notion, Zoom\\nUnknown\\nAPI\\nStable Beluga\\nStability AI\\nUndisclosed\\n7, 13, and 70 billion\\nOpen source\\nStableLM\\nStability AI\\nUndisclosed\\n7, 13, and 70 billion\\nOpen source\\nCoral\\nCohere\\nHyperWrite, Jasper, Notion, LongShot\\nUnknown\\nAPI\\nFalcon\\nTechnology Innovation Institute\\nUndisclosed\\n1.3, 7.5, 40, and 180 billion\\nOpen source\\nMPT\\nMosaic\\nUndisclosed\\n7 and 30 billion\\nOpen source\\nMixtral 8x7B\\nMistral AI\\nUndisclosed\\n46.7 billion\\nOpen source\\nXGen-7B\\nSalesforce\\nUndisclosed\\n7 billion\\nOpen source\\nGrok\\nxAI\\nGrok Chatbot\\nUnknown\\nChatbot\\nWhat is an LLM?\\nAn LLM, or large language model, is a general-purpose AI text generator. Related articles\\nApp tips\\nHow to wrap text in Google Sheets\\nHow to wrap text in Google Sheets\\nApp tips\\nHow to use Trello as a CRM\\nHow to use Trello as a CRM\\nApp tips\\nHow to record a Zoom meeting\\nHow to record a Zoom meeting\\nApp tips\\nHow to set Slack reminders\\nHow to set Slack reminders\\nImprove your productivity automatically. By company size\\nHow Zapier Zaps\\nHow Zapier’s RevOps team automates lead management\\nHow Zapier Uses AI\\nUsing AI & Zapier in Marketing, Sales, & RevOps\\nBy team\\nLearn more\\nGet help\\nZapier quick-start guide\\nCreate your first Zap with ease\\nDeveloper resources\\nHome\\nProductivity\\nApp tips\\nApp tips\\nThe best large language models (LLMs) in 2024\\n Create blog posts based on keywords with Claude and save in Google Sheets\\nWrite AI-generated email responses with Claude and store in Gmail\\nCreate AI-generated social media posts with Claude\\nStable Beluga and StableLM\\nDeveloper: Stability AI\\nParameters: 7 billion, 13 billion, and 70 billion\\nAccess: Open source\\nStability AI is the group behind Stable Diffusion, one of the best AI image generators. Translating text from one language to another\\nConverting text into computer code, or one language into another\\nGenerating social media posts, blog posts, and other marketing copy\\nSentiment analysis\\nModerating content\\nCorrecting and editing writing\\nData analysis\\n'},\n",
       " {'url': 'https://openai.com/research/better-language-models/',\n",
       "  'content': 'GPT-2 is a large transformer (opens in a new window)-based language model with 1.5 billion parameters, trained on a dataset A of 8 million web pages. GPT-2 is trained with a simple objective: predict the next word, given all of the previous words within some text. The diversity of the dataset causes this simple goal to contain naturally ...'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:22.210836Z",
     "start_time": "2024-05-20T08:03:22.195837Z"
    }
   },
   "cell_type": "code",
   "source": "tools = [retriever_tool, search] # We have two tools. One of them is a retriever and the other is a search tool.",
   "id": "ff7b9256eadbf80d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The tools to be used have been set, now we will create the agent. The agent will use the tools to interact with other agents.",
   "id": "c863a81341902516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:03:22.242186Z",
     "start_time": "2024-05-20T08:03:22.211837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We created a model to guide the agent\n",
    "from langchain_openai import ChatOpenAI # ChatOpenAI is a class that uses OpenAI to interact with the language model \n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature=0\n",
    ") # We created a model to interact with the language model. "
   ],
   "id": "a369120f9705b387",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:04:03.949848Z",
     "start_time": "2024-05-20T08:04:00.530657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we will write a prompt to direct the agent. We will use a ready-made prompt template.\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\") # We pulled the prompt template from the hub. https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ],
   "id": "62a57c4f77b37478",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:04:06.371541Z",
     "start_time": "2024-05-20T08:04:06.357513Z"
    }
   },
   "cell_type": "code",
   "source": "prompt.messages # We can see the messages in the prompt.",
   "id": "c44cce85238cfd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we will initialize an agent using model, tool and prompt.\n",
    "\n",
    "The prompt and agent are responsible for receiving input and deciding what actions to take."
   ],
   "id": "274fbab5a28c82d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:08:53.895307Z",
     "start_time": "2024-05-20T08:08:53.880788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_openai_functions_agent # Create an agent that uses OpenAI function calling.\n",
    "\n",
    "agent = create_openai_functions_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt\n",
    ") # We created an agent to interact with the language model.\n",
    "agent"
   ],
   "id": "616ee8e419a6681d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023F78FE8CD0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F78FEA3E0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'langgraph_search', 'description': 'Search for information about LangGraph. For any question about LangGraph, you must use this tool!', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}, {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}]})\n",
       "| OpenAIFunctionsAgentOutputParser()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:11:15.196026Z",
     "start_time": "2024-05-20T08:11:15.177001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools,\n",
    "    verbose=True, # If True, print the agent's messages.\n",
    ") # We created an agent executor to execute the agent."
   ],
   "id": "33fa29d6f83120ef",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:12:03.105300Z",
     "start_time": "2024-05-20T08:12:01.757215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Hi!?\", # The input message to the agent.\n",
    "    }\n",
    ") # We executed the agent."
   ],
   "id": "721d6e87a97ba4d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi!?', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:12:53.790334Z",
     "start_time": "2024-05-20T08:12:48.390544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the weather in Istanbul?\", # The input message to the agent.\n",
    "    }\n",
    ")"
   ],
   "id": "d1bed4a6390ab5db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in Istanbul'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Istanbul', 'region': 'Istanbul', 'country': 'Turkey', 'lat': 41.02, 'lon': 28.96, 'tz_id': 'Europe/Istanbul', 'localtime_epoch': 1716192750, 'localtime': '2024-05-20 11:12'}, 'current': {'last_updated_epoch': 1716192000, 'last_updated': '2024-05-20 11:00', 'temp_c': 19.0, 'temp_f': 66.2, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 11.9, 'wind_kph': 19.1, 'wind_degree': 20, 'wind_dir': 'NNE', 'pressure_mb': 1015.0, 'pressure_in': 29.97, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 64, 'cloud': 50, 'feelslike_c': 19.0, 'feelslike_f': 66.2, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 6.0, 'gust_mph': 16.3, 'gust_kph': 26.3}}\"}, {'url': 'https://www.accuweather.com/en/tr/istanbul/318251/current-weather/318251', 'content': 'Current weather in Istanbul, Istanbul, Türkiye. Check current conditions in Istanbul, Istanbul, Türkiye with radar, hourly, and more.'}, {'url': 'https://www.timeanddate.com/weather/turkey/istanbul/ext', 'content': 'Istanbul 14 Day Extended Forecast. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 57 °F. Clear. (Weather station: Istanbul Ataturk Airport, Turkey). See more current weather.'}, {'url': 'https://www.weathertab.com/en/c/e/05/republic-of-turkey/istanbul/istanbul/', 'content': 'Explore comprehensive May 2024 weather forecasts for İstanbul, including daily high and low temperatures, precipitation risks, and monthly temperature trends. Featuring detailed day-by-day forecasts, dynamic graphs of daily rain probabilities, and temperature trends to help you plan ahead. ... 20 71°F 55°F 22°C 13°C 21% 21 72°F 55°F 22 ...'}, {'url': 'https://www.wunderground.com/history/daily/tr/istanbul/IISTAN10/date/2024-5-20', 'content': 'Current Weather for Popular Cities . San Francisco, CA 54 ° F Clear; Manhattan, NY 57 ° F Clear; Schiller Park, IL (60176) 61 ° F Partly Cloudy; Boston, MA 53 ° F Mostly Cloudy; Houston, TX ...'}]\u001B[0m\u001B[32;1m\u001B[1;3mThe current weather in Istanbul is partly cloudy with a temperature of 19.0°C (66.2°F). The wind speed is 19.1 km/h coming from the north-northeast direction. The humidity is at 64%, and the visibility is 10.0 km.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather in Istanbul?',\n",
       " 'output': 'The current weather in Istanbul is partly cloudy with a temperature of 19.0°C (66.2°F). The wind speed is 19.1 km/h coming from the north-northeast direction. The humidity is at 64%, and the visibility is 10.0 km.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To provide weather information, the agent gave us information using the tavily search engine. He provided us with information by obtaining information from certain websites.\n",
    "\n",
    "We used two tools. Now we will ask the agent about the langgraph and this time we will use the retriever tool. Agent will use the retriever tool to get the information."
   ],
   "id": "cedbfa5821d1d4ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:17:48.713393Z",
     "start_time": "2024-05-20T08:17:48.705392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Can I use LangGraph for agent runtimes?\"), # We asked the agent about the langgraph.\n",
    "    AIMessage(content=\"Yes\"),\n",
    "] # We created a chat history to interact with the agent."
   ],
   "id": "e879fafa04eaaeca",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will interact with the agent using the chat history we created.",
   "id": "cab39b0330aff274"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T08:18:39.657057Z",
     "start_time": "2024-05-20T08:18:32.999135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": \"Tell me how\", # The input message to the agent.\n",
    "    }\n",
    ") # We executed the agent."
   ],
   "id": "fe7427ad16c9510d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `langgraph_search` with `{'query': 'using LangGraph for agent runtimes'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mTL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.Python RepoPython YouTube PlaylistJS RepoIntroductionOne of the things we highlighted in our LangChain v0.1 announcement was the introduction of a new library: LangGraph. LangGraph is built on top of LangChain and completely interoperable with the LangChain ecosystem. It adds new value primarily through the introduction of an easy way to create cyclical graphs. This is often useful when creating agent runtimes.In this blog post, we will first walk through the motivations for LangGraph. We will then cover the basic functionality it provides. We will then spotlight two agent runtimes we've implemented already. We will then highlight a few of the common modifications to these runtimes we've heard requests for, and examples of implementing those. We will finish with a preview of what we will be releasing next.MotivationOne of the big value props of LangChain is the ability to easily create custom chains. We've invested heavily in the functionality for this with LangChain Expression Language. However, so far we've lacked a method for easily introducing cycles into these chains. Effectively, these chains are directed acyclic graphs (DAGs) - as are most data orchestration frameworks.One of the common patterns we see when people are creating more complex LLM applications is the introduction of cycles into the runtime. These cycles often use the LLM to reason about what to do next in the cycle. A big unlock of LLMs is the ability to use them for these reasoning tasks. This can essentially be thought of as running an LLM in a for-loop. These types of systems are often called agents.An example of why this agentic behavior can be so powerful can be found when considering a typical retrieval augmented generation (RAG) application. In a typical RAG application, a call to a retriever is made that returns some documents. These documents are then passed to an LLM to generate a final answer. While this is often effective, it breaks down in cases when the first retrieval step fails to return any useful results. In this case, it's often ideal if the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever, and use those results instead. Essentially, running an LLM in a loop helps create applications that are more flexible and thus can accomplish more vague use-cases that may not be predefined.These types of applications are often called agents. The simplest - but at the same time most ambitious - form of these is a loop that essentially has two steps:Call the LLM to determine either (a) what actions to take, or (b) what response to give the userTake given actions, and pass back to step 1These steps are repeated until a final response is generated. This is essentially the loop that powers our core AgentExecutor, and is the same logic that caused projects like AutoGPT to rise in prominence. This is simple because it is a relatively simple loop. It is the most ambitious because it offloads pretty much ALL of the decision making and reasoning ability to the LLM.One thing we've seen in practice as we've worked the community and companies to put agents into production is that often times more control is needed. You may want to always force an agent to call particular tool first. You may want have more control over how tools are called. You may want to have different prompts for the agent, depending on that state it is in.When talking about these more controlled flows, we internally refer to them as \"state machines\". See the below diagram from our blog on cognitive architectures.These state machines have the power of being able to loop - allowing for handling of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by\n",
      "\n",
      "of more ambiguous inputs than simple chains. However, there is still an element of human guidance in terms of how that loop is constructed.LangGraph is a way to create these state machines by specifying them as graphs.FunctionalityAt it's core, LangGraph exposes a pretty narrow interface on top of LangChain.StateGraphStateGraph is a class that represents the graph. You initialize this class by passing in a state definition. This state definition represents a central state object that is updated over time. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store).The attributes of this state can be updated in two ways. First, an attribute could be overridden completely. This is useful if you want to nodes to return the new value of an attribute. Second, an attribute could be updated by adding to its value. This is useful if an attribute is a list of actions taken (or something similar) and you want nodes to return new actions taken (and have those automatically added to the attribute).You specify whether an attribute should be overridden or added to when creating the initial state definition. See an example in pseudocode below.from langgraph.graph import StateGraph\n",
      "\n",
      "LangGraph\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Release Notes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangGraph\n",
      "\n",
      "By LangChain\n",
      "7 min read\n",
      "Jan 17, 2024\n",
      "\n",
      "class State(TypedDict):\n",
      "    input: str\n",
      "    all_actions: Annotated[List[str], operator.add]\n",
      "\n",
      "\n",
      "graph = StateGraph(State)NodesAfter creating a StateGraph, you then add nodes with graph.add_node(name, value) syntax. The name parameter should be a string that we will use to refer to the node when adding edges. The value parameter should be either a function or LCEL runnable that will be called. This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.See an example in pseudocode below.graph.add_node(\"model\", model)\n",
      "graph.add_node(\"tools\", tool_executor)There is also a special END node that is used to represent the end of the graph. It is important that your cycles be able to end eventually!from langgraph.graph import ENDEdgesAfter adding nodes, you can then add edges to create the graph. There are a few types of edges.The Starting EdgeThis is the edge that connects the start of the graph to a particular node. This will make it so that that node is the first one called when input is passed to the graph. Pseudocode for that is:graph.set_entry_point(\"model\")Normal EdgesThese are edges where one node should ALWAYS be called after another. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool.graph.add_edge(\"tools\", \"model\")Conditional EdgesThese are where a function (often powered by an LLM) is used to determine which node to go to first. To create this edge, you need to pass in three things:The upstream node: the output of this node will be looked at to determine what to do nextA function: this will be called to determine which node to call next. It should return a stringA mapping: this mapping will be used to map the output of the function in (2) to another node. The keys should be possible values that the function in (2) could return. The values should be names of nodes to go to if that value is returned.An example of this could be that after a model is called we either exit the graph and return to the user, or we call a tool - depending on what a user decides! See an example in pseudocode below:graph.add_conditional_edge(\n",
      "    \"model\",\n",
      "    should_continue,\n",
      "    {\n",
      "        \"end\": END,\n",
      "        \"continue\": \"tools\"\n",
      "    }\n",
      ")CompileAfter we define our graph, we can compile it into a runnable! This simply takes the graph definition we've created so far an returns a runnable. This runnable exposes all the same method as LangChain runnables (.invoke, .stream, .astream_log, etc) allowing it to be called in the same manner as a chain.app = graph.compile()Agent ExecutorWe've recreated the canonical LangChain AgentExecutor with LangGraph. This will allow you to use existing LangChain agents, but allow you to more easily modify the internals of the AgentExecutor. The state of this graph by default contains concepts that should be familiar to you if you've used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)from typing import TypedDict, Annotated, List, Union\n",
      "from langchain_core.agents import AgentAction, AgentFinish\n",
      "from langchain_core.messages import BaseMessage\n",
      "import operator\u001B[0m\u001B[32;1m\u001B[1;3mLangGraph is a module built on top of LangChain that enables the creation of cyclical graphs, which are often needed for agent runtimes. LangGraph provides functionality through the StateGraph class, which represents the graph and allows for the addition of nodes and edges. Nodes in the graph update a central state object over time, and edges connect the nodes to create the flow of the graph.\n",
      "\n",
      "To use LangGraph for agent runtimes, you can follow these steps:\n",
      "1. Initialize a StateGraph by passing in a state definition.\n",
      "2. Add nodes to the graph using the `graph.add_node(name, value)` syntax, where the name is a string to refer to the node and the value is a function or LCEL runnable.\n",
      "3. Add edges to connect the nodes in the graph, including starting edges, normal edges, and conditional edges.\n",
      "4. Compile the graph into a runnable using `graph.compile()`.\n",
      "5. Use the AgentExecutor provided by LangGraph to modify the internals of the agent runtime and interact with the graph.\n",
      "\n",
      "By following these steps, you can leverage LangGraph to create agent runtimes with cyclical graphs for more flexible and powerful applications.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can I use LangGraph for agent runtimes?'),\n",
       "  AIMessage(content='Yes')],\n",
       " 'input': 'Tell me how',\n",
       " 'output': 'LangGraph is a module built on top of LangChain that enables the creation of cyclical graphs, which are often needed for agent runtimes. LangGraph provides functionality through the StateGraph class, which represents the graph and allows for the addition of nodes and edges. Nodes in the graph update a central state object over time, and edges connect the nodes to create the flow of the graph.\\n\\nTo use LangGraph for agent runtimes, you can follow these steps:\\n1. Initialize a StateGraph by passing in a state definition.\\n2. Add nodes to the graph using the `graph.add_node(name, value)` syntax, where the name is a string to refer to the node and the value is a function or LCEL runnable.\\n3. Add edges to connect the nodes in the graph, including starting edges, normal edges, and conditional edges.\\n4. Compile the graph into a runnable using `graph.compile()`.\\n5. Use the AgentExecutor provided by LangGraph to modify the internals of the agent runtime and interact with the graph.\\n\\nBy following these steps, you can leverage LangGraph to create agent runtimes with cyclical graphs for more flexible and powerful applications.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The agent fulfilled the tasks I gave him. He made the decision himself while performing these duties. Tavily and retriever evaluated the tools according to the input given and presented us with the results accordingly.",
   "id": "d3891e152f0118ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
