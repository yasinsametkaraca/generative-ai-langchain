{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T07:48:30.256371Z",
     "start_time": "2024-05-17T07:48:30.238033Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T07:48:30.288390Z",
     "start_time": "2024-05-17T07:48:30.259372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5, # Temperature means how much randomness is added to the output. 0.5 is the default. Lower values are more deterministic, higher values more random.\n",
    ")"
   ],
   "id": "8373e9945f0e050",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T07:48:31.297650Z",
     "start_time": "2024-05-17T07:48:30.290370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"When was Mustafa Kemal Ataturk born?\"\n",
    "\n",
    "response = chat_model.invoke(text) # Invoke the model with the text input and get the response back. Invoke is the same as calling the model.\n",
    "response"
   ],
   "id": "882cfb3cfae2de6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mustafa Kemal Ataturk was born on May 19, 1881.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 18, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ca6c413e-0720-4c8b-a279-9bee7bc9f9e5-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T07:48:31.328456Z",
     "start_time": "2024-05-17T07:48:31.300927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import HuggingFaceHub # huggingface.co model hub. This site has a lot of models that you can use. You can also upload your own models to this site.\n",
    "import os\n",
    "\n",
    "hugging_face_model = HuggingFaceHub(\n",
    "    repo_id=\"flan-t5-large\",\n",
    "    model_kwargs={\"temperature\":0.7, \"max_length\": 100}, # You can pass in any model kwargs that you want to use. These are the default values. max_length is the maximum length of the output. If the output is longer than this, it will be truncated.\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACE_API_TOKEN\"],\n",
    ") # Load the model from the huggingface.co model hub. Flan-t5-large is a model that is trained on the Flan dataset."
   ],
   "id": "8a55b1485a52ebd0",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HUGGINGFACE_API_TOKEN'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceHub \u001B[38;5;66;03m# huggingface.co model hub. This site has a lot of models that you can use. You can also upload your own models to this site.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      4\u001B[0m hugging_face_model \u001B[38;5;241m=\u001B[39m HuggingFaceHub(\n\u001B[0;32m      5\u001B[0m     repo_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflan-t5-large\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m100\u001B[39m}, \u001B[38;5;66;03m# You can pass in any model kwargs that you want to use. These are the default values. max_length is the maximum length of the output. If the output is longer than this, it will be truncated.\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m     huggingfacehub_api_token\u001B[38;5;241m=\u001B[39m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHUGGINGFACE_API_TOKEN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m,\n\u001B[0;32m      8\u001B[0m ) \u001B[38;5;66;03m# Load the model from the huggingface.co model hub. Flan-t5-large is a model that is trained on the Flan dataset.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py:679\u001B[0m, in \u001B[0;36m_Environ.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    676\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencodekey(key)]\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;66;03m# raise KeyError with the original key value\u001B[39;00m\n\u001B[1;32m--> 679\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecodevalue(value)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'HUGGINGFACE_API_TOKEN'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T07:48:31.329576Z",
     "start_time": "2024-05-17T07:48:31.329576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = hugging_face_model.invoke(text)\n",
    "output"
   ],
   "id": "236333712aaf4ab4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:00:47.052956Z",
     "start_time": "2024-05-17T08:00:47.042952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Large language models (llm) take strings, i.e. text, as input and produce text as output; chat models take a list of messages as input and produce messages as output.\n",
    "\n",
    "text = \"Tell me about the history of Turkey.\"\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=text)] # Create a list of HumanMessage objects. Each message has a content attribute that is the text of the message. \n",
    "messages"
   ],
   "id": "a0b61ea3078f58b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me about the history of Turkey.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:01:10.449059Z",
     "start_time": "2024-05-17T08:01:10.405173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "\n",
    "llm = OpenAI() # Big model with a lot of parameters. This model is more powerful than the other models, but it is also more expensive to use.\n",
    "chat_model = ChatOpenAI() # chat model is a smaller model that is more cost-effective to use. It is good for chatbots and other applications where you need to generate a lot of text."
   ],
   "id": "a6c9d6feb5a3895b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:01:17.280747Z",
     "start_time": "2024-05-17T08:01:11.480247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_output = llm.invoke(text) # Invoke the large language model with the text input. The output is a list of messages.\n",
    "llm_output"
   ],
   "id": "97f4abb3de33d110",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe history of Turkey dates back to ancient times, with the region being inhabited by various civilizations such as the Hittites, Phrygians, Greeks, Persians, and Romans. In the 11th century, the Seljuk Turks migrated to the region and established the Seljuk Sultanate of Rum, which lasted until the Mongol invasions in the 13th century.\\n\\nIn the 14th century, the Ottoman Empire emerged under the leadership of Osman I. The Ottomans expanded their territory, conquering Constantinople in 1453 and establishing the city as their capital. The empire reached its peak under the rule of Suleiman the Magnificent in the 16th century, becoming a major power in Europe and the Middle East.\\n\\nThe decline of the Ottoman Empire began in the late 17th century, with frequent wars and internal conflicts leading to a gradual loss of territory. In the 19th century, the empire became known as the \"Sick Man of Europe\" as it struggled to modernize and keep up with the advancements of Western powers.\\n\\nIn the early 20th century, the Ottoman Empire was dissolved after its defeat in World War I. Mustafa Kemal Atat√ºrk led the Turkish War of'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:01:33.855364Z",
     "start_time": "2024-05-17T08:01:24.796704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_output = chat_model.invoke(messages) # Invoke the chat model with the list of messages. The output is a list of messages.\n",
    "chat_output"
   ],
   "id": "1f16049c6bc068ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The history of Turkey dates back to ancient times, with the region being home to several ancient civilizations, such as the Hittites, Phrygians, and Lydians. The area known as modern-day Turkey was also part of the Byzantine Empire and later the Ottoman Empire.\\n\\nThe Seljuk Turks established themselves in Anatolia in the 11th century, and by the 13th century, they had founded the Sultanate of Rum. The Ottoman Empire, founded in the late 13th century, expanded rapidly and became a major power in the region, eventually conquering Constantinople in 1453 and establishing the Ottoman Caliphate.\\n\\nThe Ottoman Empire reached its peak in the 16th century, controlling vast territories in Europe, Africa, and Asia. However, by the 19th century, the empire began to decline, losing territories and facing internal strife.\\n\\nDuring World War I, the Ottoman Empire sided with the Central Powers and was defeated. After the war, the empire was dissolved, and modern-day Turkey emerged as a republic in 1923 under the leadership of Mustafa Kemal Atat√ºrk.\\n\\nUnder Atat√ºrk's leadership, Turkey underwent significant reforms, including the adoption of a new legal system, the establishment of a secular government, and the introduction of Western-style education and culture. Turkey also became a member of NATO in 1952 and applied for membership in the European Union in 1987.\\n\\nIn recent years, Turkey has faced various challenges, including political unrest, economic instability, and tensions with neighboring countries. Despite these challenges, Turkey remains an important player in the region and continues to strive for democracy, stability, and economic prosperity.\", response_metadata={'token_usage': {'completion_tokens': 341, 'prompt_tokens': 15, 'total_tokens': 356}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-88a4d309-f46e-4c54-869b-9745b7741339-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
