{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chains\n",
    "chains means in langchain that we can chain multiple functions together. Like a pipeline."
   ],
   "id": "246193d1aa67b0fd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:14:27.785481Z",
     "start_time": "2024-05-17T09:14:27.760047Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:19:33.497366Z",
     "start_time": "2024-05-17T09:19:32.099498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {content}.\"\n",
    ")"
   ],
   "id": "3db03fcca6f5d979",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:20:01.410186Z",
     "start_time": "2024-05-17T09:20:01.389731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template.format(\n",
    "    adjective=\"funny\",\n",
    "    content=\"a cat and a dog\"\n",
    ")"
   ],
   "id": "e410a410eab2f124",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny story about a cat and a dog.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LCEL: Language Chain Execution Language is a language that allows you to chain multiple functions together. Declarative programming. Declarative programming is a programming paradigm that expresses the logic of a computation without describing its control flow.",
   "id": "69354e9ec6e49020"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:09.356020Z",
     "start_time": "2024-05-17T09:31:08.636208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ],
   "id": "b3452b3117dbf167",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:33:10.172327Z",
     "start_time": "2024-05-17T09:33:08.590310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.invoke(\"Give me a suggestion for the main course for today's dinner.\")\n",
    "print(response.content)"
   ],
   "id": "6113451d90e338a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How about trying a delicious and hearty beef stroganoff served over egg noodles? It's a classic dish that is sure to satisfy everyone at the dinner table.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:35:47.675956Z",
     "start_time": "2024-05-17T09:35:47.658567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Give me a suggestion for the {content} for today's dinner.\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()"
   ],
   "id": "8558f40b725f0a3e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:35:51.820859Z",
     "start_time": "2024-05-17T09:35:51.809352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ],
   "id": "1ca4de21abc8fc27",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can chain with the sign (|). The sign turns the output of one function into the input of another function.",
   "id": "fb8ea82f1b932c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:37:54.189243Z",
     "start_time": "2024-05-17T09:37:54.186003Z"
    }
   },
   "cell_type": "code",
   "source": "chain = prompt | model | output_parser # chain is a function that takes an input and returns an output. Prompt -> Model -> OutputParser ",
   "id": "414893f64dc83121",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:38:46.301170Z",
     "start_time": "2024-05-17T09:38:44.532436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain.invoke({\n",
    "    \"content\": \"main course\"\n",
    "})"
   ],
   "id": "f0ff74d04c448d45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How about a delicious roasted lemon and herb chicken served with garlic mashed potatoes and roasted vegetables? It's a classic and comforting dish that is sure to be a hit with everyone at the table.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:46:05.783424Z",
     "start_time": "2024-05-17T09:46:04.131963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are an English-Turkish translator that return whatever the user says in Turkish.\"),\n",
    "    (\"user\", \"{input}\")]\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"input\": \"Hello, how are you?\"})"
   ],
   "id": "a41f9211b0c0c759",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merhaba, nasılsınız?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PromptTemplate.from_template: Use PromptTemplate to create a template for a string prompt.\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "\n",
    "\n",
    "\n",
    "ChatPromptTemplate.from_messages: The prompt to chat models/ is a list of chat messages. Each chat message is associated with content, and an additional parameter called role. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role.\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ],
   "id": "da66d4e65b0ccdfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
